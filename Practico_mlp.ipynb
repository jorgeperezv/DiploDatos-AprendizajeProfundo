{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gzip\n",
    "import json\n",
    "import mlflow\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_data = \"./data/meli-challenge-2019/spanish.train.jsonl.gz\"\n",
    "_validation_data = \"./data/meli-challenge-2019/spanish.validation.jsonl.gz\"\n",
    "_test_data = \"./data/meli-challenge-2019/spanish.test.jsonl.gz\"\n",
    "_token_to_index = \"./data/meli-challenge-2019/spanish_token_to_index.json.gz\"\n",
    "_pretrained_embeddings = \"./data/SBW-vectors-300-min5.txt.gz\"\n",
    "_language = \"spanish\"\n",
    "_embeddings_size = 300\n",
    "_hidden_layers = [512, 256, 256, 128]\n",
    "_epochs = 5\n",
    "_dropout = 0.3\n",
    "_batch_size = 128\n",
    "_freeze_embedings = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeliChallengeDataset(IterableDataset):\n",
    "    def __init__(self,\n",
    "                 dataset_path,\n",
    "                 random_buffer_size=2048):\n",
    "        assert random_buffer_size > 0\n",
    "        self.dataset_path = dataset_path\n",
    "        self.random_buffer_size = random_buffer_size\n",
    "\n",
    "        with gzip.open(self.dataset_path, \"rt\") as dataset:\n",
    "            item = json.loads(next(dataset).strip())\n",
    "            self.n_labels = item[\"n_labels\"]\n",
    "            self.dataset_size = item[\"size\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        try:\n",
    "            with gzip.open(self.dataset_path, \"rt\") as dataset:\n",
    "                shuffle_buffer = []\n",
    "\n",
    "                for line in dataset:\n",
    "                    item = json.loads(line.strip())\n",
    "                    item = {\n",
    "                        \"data\": item[\"data\"],\n",
    "                        \"target\": item[\"target\"]\n",
    "                    }\n",
    "\n",
    "                    if self.random_buffer_size == 1:\n",
    "                        yield item\n",
    "                    else:\n",
    "                        shuffle_buffer.append(item)\n",
    "\n",
    "                        if len(shuffle_buffer) == self.random_buffer_size:\n",
    "                            random.shuffle(shuffle_buffer)\n",
    "                            for item in shuffle_buffer:\n",
    "                                yield item\n",
    "                            shuffle_buffer = []\n",
    "\n",
    "                if len(shuffle_buffer) > 0:\n",
    "                    random.shuffle(shuffle_buffer)\n",
    "                    for item in shuffle_buffer:\n",
    "                        yield item\n",
    "        except GeneratorExit:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSequences:\n",
    "    def __init__(self, pad_value=0, max_length=None, min_length=1):\n",
    "        assert max_length is None or min_length <= max_length\n",
    "        self.pad_value = pad_value\n",
    "        self.max_length = max_length\n",
    "        self.min_length = min_length\n",
    "\n",
    "    def __call__(self, items):\n",
    "        data, target = list(zip(*[(item[\"data\"], item[\"target\"]) for item in items]))\n",
    "        seq_lengths = [len(d) for d in data]\n",
    "\n",
    "        if self.max_length:\n",
    "            max_length = self.max_length\n",
    "            seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n",
    "        else:\n",
    "            max_length = max(self.min_length, max(seq_lengths))\n",
    "\n",
    "        data = [d[:l] + [self.pad_value] * (max_length - l)\n",
    "                for d, l in zip(data, seq_lengths)]\n",
    "            \n",
    "        return {\n",
    "            \"data\": torch.LongTensor(data),\n",
    "            \"target\": torch.LongTensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sequences = PadSequences(\n",
    "    pad_value=0,\n",
    "    max_length=None,\n",
    "    min_length=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building training dataset\n",
    "train_dataset = MeliChallengeDataset(\n",
    "    dataset_path=_train_data,\n",
    "    random_buffer_size=2048  # This can be a hypterparameter\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=_batch_size,  # This can be a hyperparameter\n",
    "    shuffle=False,\n",
    "    collate_fn=pad_sequences,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building validation dataset\n",
    "validation_dataset = MeliChallengeDataset(\n",
    "    dataset_path=_validation_data,\n",
    "    random_buffer_size=1\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=pad_sequences,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building test dataset\n",
    "test_dataset = MeliChallengeDataset(\n",
    "    dataset_path=_test_data,\n",
    "    random_buffer_size=1\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=pad_sequences,\n",
    "    drop_last=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de clasificación MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 pretrained_embeddings_path,\n",
    "                 token_to_index,\n",
    "                 n_labels,\n",
    "                 hidden_layers=[256, 128],\n",
    "                 dropout=0.3,\n",
    "                 vector_size=300,\n",
    "                 freeze_embedings=True):\n",
    "        super().__init__()\n",
    "        with gzip.open(token_to_index, \"rt\") as fh:\n",
    "            token_to_index = json.load(fh)\n",
    "        embeddings_matrix = torch.randn(len(token_to_index), vector_size)\n",
    "        embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "        with gzip.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            next(fh)\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in token_to_index:\n",
    "                    embeddings_matrix[token_to_index[word]] =\\\n",
    "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                                       freeze=freeze_embedings,\n",
    "                                                       padding_idx=0)\n",
    "        self.hidden_layers = [\n",
    "            nn.Linear(vector_size, hidden_layers[0])\n",
    "        ]\n",
    "        for input_size, output_size in zip(hidden_layers[:-1], hidden_layers[1:]):\n",
    "            self.hidden_layers.append(\n",
    "                nn.Linear(input_size, output_size)\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers)\n",
    "        self.output = nn.Linear(hidden_layers[-1], n_labels)\n",
    "        self.vector_size = vector_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            if self.dropout:\n",
    "                x = F.dropout(x, self.dropout)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    pretrained_embeddings_path=_pretrained_embeddings,\n",
    "    token_to_index=_token_to_index,\n",
    "    n_labels=train_dataset.n_labels,\n",
    "    hidden_layers=_hidden_layers,\n",
    "    dropout=_dropout,\n",
    "    vector_size=_embeddings_size,\n",
    "    freeze_embedings=_freeze_embedings  # This can be a hyperparameter\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(\n",
      "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=300, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=632, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento de MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267a733bb26c46598a4a113c52bb9e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465c8badc90a44b5a672e025bda1bce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=38245.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604c707c96214ef885082afb69bf78bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5b42806e184d0a91e3377d6f3a0167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=38245.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad84ff774c940b3926eaf447bdcb0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f10a380878d43dabf3707585b4bc633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=38245.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5190807fcba41b3aebb1a615f748530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc533c12c7cb468fb9bfd86fc60d025c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=38245.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60888a4c85b4cc28b2d2b2fab9bdcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ea573ef6a748cbac5d6c7df450b3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=38245.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc08a75d45b4c41a309306b5b39828e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca9abd905af4b919d9607972d011b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=498.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Práctico MLP\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log all relevent hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"model_type\": \"Multilayer Perceptron\",\n",
    "        \"embeddings\": _pretrained_embeddings,\n",
    "        \"hidden_layers\": _hidden_layers,\n",
    "        \"dropout\": _dropout,\n",
    "        \"batch_size\": _batch_size,\n",
    "        \"freeze_embedings\": _freeze_embedings,\n",
    "        \"embeddings_size\": _embeddings_size,\n",
    "        \"epochs\": _epochs        \n",
    "    })\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=1e-3,  # This can be a hyperparameter\n",
    "        weight_decay=1e-5  # This can be a hyperparameter\n",
    "    )\n",
    "\n",
    "    for epoch in trange(_epochs):\n",
    "        model.train()\n",
    "        running_loss = []\n",
    "        for idx, batch in enumerate(tqdm(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            data = batch[\"data\"].to(device)\n",
    "            target = batch[\"target\"].to(device)\n",
    "            output = model(data)\n",
    "            loss_value = loss(output, target)\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss_value.item())\n",
    "        mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "\n",
    "        if validation_dataset:\n",
    "            model.eval()\n",
    "            running_loss = []\n",
    "            targets = []\n",
    "            predictions = []\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(validation_loader):\n",
    "                    data = batch[\"data\"].to(device)\n",
    "                    target = batch[\"target\"].to(device)\n",
    "                    output = model(data)\n",
    "                    running_loss.append(\n",
    "                        loss(output, target).item()\n",
    "                    )\n",
    "                    targets.extend(batch[\"target\"].numpy())\n",
    "                    predictions.extend(output.argmax(axis=1).detach().cpu().numpy())\n",
    "                mlflow.log_metric(\"validation_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "                mlflow.log_metric(\"validation_bacc\", balanced_accuracy_score(targets, predictions), epoch)\n",
    "\n",
    "    if test_dataset:\n",
    "        model.eval()\n",
    "        running_loss = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader):\n",
    "                data = batch[\"data\"].to(device)\n",
    "                target = batch[\"target\"].to(device)\n",
    "                output = model(data)\n",
    "                running_loss.append(\n",
    "                    loss(output, target).item()\n",
    "                )\n",
    "                targets.extend(batch[\"target\"].numpy())\n",
    "                predictions.extend(output.argmax(axis=1).detach().cpu().numpy())\n",
    "            mlflow.log_metric(\"test_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "            mlflow.log_metric(\"test_bacc\", balanced_accuracy_score(targets, predictions), epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
